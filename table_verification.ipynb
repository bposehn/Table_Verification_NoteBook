{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum   \n",
    "\n",
    "class System(Enum):\n",
    "    PI3 = 1\n",
    "    PI4 = 2\n",
    "    FDP = 3\n",
    "\n",
    "system_in_use = System.PI3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create verification object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1728457 Rows\n"
     ]
    }
   ],
   "source": [
    "backend_cs_dll = 'table_verification_cs/bin/Debug/'\n",
    "sys.path.append(backend_cs_dll)\n",
    "\n",
    "import clr\n",
    "clr.AddReference('table_verification_cs')\n",
    "\n",
    "from TableVerification import TableVerifier, FailingProfile\n",
    "\n",
    "tv = TableVerifier(\"pi3b_asbuilt_pfc17500ab_2022-06-09\", \"B161087,B211100,B261087,B291060,B215008,B261008\")\n",
    "print(f\"Read {tv.GetNumRowsInDatatable()} Rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All profile check duration: 77499\n"
     ]
    }
   ],
   "source": [
    "tv.GenerateProfileScores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "failing_profiles = tv.GetFailingProfiles(.5)\n",
    "print(len(failing_profiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import clr\n",
    "\n",
    "clr.AddReference('System')\n",
    "from System import Array\n",
    "\n",
    "sys.path.append(os.getenv(\"AURORA_REPOS\"))\n",
    "\n",
    "from flagships.post_processing.GenerateColumns import get_full_file_path\n",
    "from flagships.post_processing.ParseFlagshipsFile import FlagshipsParser\n",
    "from flagships.post_processing.EquilibriumPlotting import PlotPsi5PctContours\n",
    "\n",
    "def plotPsiContoursForProfile(failing_profile : FailingProfile, axes):\n",
    "    search_axis_name = failing_profile.SearchAxis\n",
    "    search_axis_values = list(axes[search_axis_name])\n",
    "    \n",
    "    if search_axis_values.index(failing_profile.TableParams[search_axis_name]) == 0:\n",
    "        offending_values = search_axis_values[:2]\n",
    "    elif search_axis_values.index(failing_profile.TableParams[search_axis_name]) == len(search_axis_values)-1:\n",
    "        offending_values = search_axis_values[len(search_axis_values)-2:]\n",
    "    else:\n",
    "        offending_values = search_axis_values[search_axis_values.index(failing_profile.TableParams[search_axis_name])-1:search_axis_values.index(failing_profile.TableParams[search_axis_name])+2]\n",
    "\n",
    "    failing_profile.SearchAxis\n",
    "\n",
    "    # for val in offending_values:\n",
    "    #     failing_profile.TableParams\n",
    "        # tbl_params[fp.SearchAxis] = val\n",
    "        # filepath = get_full_file_path(\"\\\\mnt\\\\lut\\\\Flagships\\\\pi3b\\\\asbuilt\\\\pfc17500ab\\\\2022-06-09\\\\equil\", \"\", \".2022-06-09\",\n",
    "        #         soak = tbl_params['psieq_soak'], beta=tbl_params['beta_pol1_setpoint'], dc=tbl_params['psieq_dc'], NevinsC=tbl_params['NevinsC'], \n",
    "        #         NevinsAB=tbl_params['NevinsA'], NevinsN=tbl_params['NevinsN'], current_ratio=tbl_params['CurrentRatio'])\n",
    "        # filepath = filepath.replace('\\\\', os.path.sep)\n",
    "        # if(not os.path.exists(filepath)):\n",
    "        #     filepath = filepath[:filepath.find('ab', filepath.find('equil'))+3] + filepath[filepath.find('ab', filepath.find('equil'))+4:]\n",
    "        # if(not os.path.exists(filepath)):\n",
    "        #     filepath = filepath[:filepath.rfind('ab')+3] + filepath[filepath.rfind('ab')+4:]\n",
    "        # if(not os.path.exists(filepath)):\n",
    "        #     print(f'File cannot be found:\\n {filepath}')\n",
    "        #     continue\n",
    "        # parser = FlagshipsParser(filepath, filepath)\n",
    "        # plt.subplot(1, len(offending_vals), i)\n",
    "        # i += 1\n",
    "        # PlotPsi5PctContours(parser)\n",
    "        # plt.title(fp.SearchAxis + f\" = {val}\")\n",
    "\n",
    "plotPsiContoursForProfile(failing_profiles[0], tv.TableAxesValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'System.Collections.Generic.0, Culture=neutral, PublicKeyToken=b77a5c561934e089]]'>\n",
      "<class 'System.Collections.Generic.0, Culture=neutral, PublicKeyToken=b77a5c561934e089]]'>\n",
      "[psieq_soak, 0.01]\n",
      "<class 'System.Collections.Generic.0, Culture=neutral, PublicKeyToken=b77a5c561934e089]]'>\n",
      "[beta_pol1_setpoint, 0.1]\n",
      "<class 'System.Collections.Generic.0, Culture=neutral, PublicKeyToken=b77a5c561934e089]]'>\n",
      "[psieq_dc, 0]\n",
      "<class 'System.Collections.Generic.0, Culture=neutral, PublicKeyToken=b77a5c561934e089]]'>\n",
      "[NevinsA, -1]\n",
      "<class 'System.Collections.Generic.0, Culture=neutral, PublicKeyToken=b77a5c561934e089]]'>\n",
      "[NevinsC, 0.26]\n",
      "<class 'System.Collections.Generic.0, Culture=neutral, PublicKeyToken=b77a5c561934e089]]'>\n",
      "[NevinsN, 3]\n",
      "<class 'System.Collections.Generic.0, Culture=neutral, PublicKeyToken=b77a5c561934e089]]'>\n",
      "[Ipl_setpoint, 100000]\n"
     ]
    }
   ],
   "source": [
    "failing_profile = failing_profiles[0]\n",
    "axes = tv.TableAxesValues\n",
    "\n",
    "search_axis_name = failing_profile.SearchAxis\n",
    "search_axis_values = axes[search_axis_name]\n",
    "\n",
    "print(type(failing_profile.TableParams))\n",
    "for pr in failing_profile.TableParams:\n",
    "    print(type(pr))\n",
    "    print(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clr\n",
    "\n",
    "clr.AddReference('System')\n",
    "from System import String, Double\n",
    "from System.Collections.Generic import Dictionary\n",
    "\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "backend_cs_dll = '/nfs/home/brendan.posehn/ws/table_verification/table_verification_cs/bin/Debug/' # get some better way to do this \n",
    "sys.path.append(backend_cs_dll)\n",
    "clr.AddReference('table_verification_cs')\n",
    "\n",
    "from TableVerification import TableVerifier, FailingProfile\n",
    "\n",
    "fp = FailingProfile()\n",
    "fp.ProfileColumnName = \"B161087\"\n",
    "fp.SearchAxis = \"NevinsA\"\n",
    "\n",
    "tbl_params = Dictionary[String, Double]()\n",
    "tbl_params['psieq_soak'] = 0.08\n",
    "tbl_params['beta_pol1_setpoint'] = 0.1\n",
    "tbl_params['psieq_dc'] = -0.08\n",
    "tbl_params['NevinsC'] = 0.44\n",
    "tbl_params['NevinsN'] = 99\n",
    "tbl_params['CurrentRatio'] = 0.5\n",
    "fp.TableParams = tbl_params\n",
    "\n",
    "fp.OffendingValue = 1\n",
    "\n",
    "offending_vals = [0, 1, 2] # get this from tableaxes later on\n",
    "\n",
    "sys.path.append(os.getenv(\"AURORA_REPOS\"))\n",
    "\n",
    "from flagships.post_processing.GenerateColumns import get_full_file_path\n",
    "from flagships.post_processing.ParseFlagshipsFile import FlagshipsParser\n",
    "from flagships.post_processing.EquilibriumPlotting import PlotPsi5PctContours\n",
    "\n",
    "i = 1\n",
    "plt.figure(figsize=(12, 6))\n",
    "for val in offending_vals:\n",
    "    tbl_params[fp.SearchAxis] = val\n",
    "    filepath = get_full_file_path(\"\\\\mnt\\\\lut\\\\Flagships\\\\pi3b\\\\asbuilt\\\\pfc17500ab\\\\2022-06-09\\\\equil\", \"\", \".2022-06-09\",\n",
    "            soak = tbl_params['psieq_soak'], beta=tbl_params['beta_pol1_setpoint'], dc=tbl_params['psieq_dc'], NevinsC=tbl_params['NevinsC'], \n",
    "            NevinsAB=tbl_params['NevinsA'], NevinsN=tbl_params['NevinsN'], current_ratio=tbl_params['CurrentRatio'])\n",
    "    filepath = filepath.replace('\\\\', os.path.sep)\n",
    "    if(not os.path.exists(filepath)):\n",
    "        filepath = filepath[:filepath.find('ab', filepath.find('equil'))+3] + filepath[filepath.find('ab', filepath.find('equil'))+4:]\n",
    "    if(not os.path.exists(filepath)):\n",
    "        filepath = filepath[:filepath.rfind('ab')+3] + filepath[filepath.rfind('ab')+4:]\n",
    "    if(not os.path.exists(filepath)):\n",
    "        print(f'File cannot be found:\\n {filepath}')\n",
    "        continue\n",
    "    parser = FlagshipsParser(filepath, filepath)\n",
    "    plt.subplot(1, len(offending_vals), i)\n",
    "    i += 1\n",
    "    PlotPsi5PctContours(parser)\n",
    "    plt.title(fp.SearchAxis + f\" = {val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Check for holes in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check for data discontinuities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "print(os.getenv(\"AURORA_REPOS\"))\n",
    "sys.path.append(os.getenv(\"AURORA_REPOS\"))\n",
    "\n",
    "from flagships.post_processing import GenerateColumns\n",
    "\n",
    "if(system_in_use == System.PI3):\n",
    "    csv_generator =  GenerateColumns.PI3CSVGenerator()\n",
    "elif(system_in_use == System.PI4):\n",
    "    csv_generator =  GenerateColumns.PI4CSVGenerator()\n",
    "elif(system_in_use == System.FDP):\n",
    "    csv_generator = GenerateColumns.FDPCase22a_CSVGenerator()\n",
    "else:\n",
    "    print('Ensure correct system is set')\n",
    "\n",
    "other_cols = ['WBPol', 'q020', 'q050', 'q080', 'WBPolNoDCInFC', 'phiPlInFC']\n",
    "b_col_names = []\n",
    "for val in csv_generator.add_bprobe_columns([]):\n",
    "    b_col_names.append('B' + val[0])\n",
    "\n",
    "profile_columns_of_interest = other_cols + b_col_names\n",
    "existent_columns_of_interest = []\n",
    "\n",
    "all_cols = csv_generator.create_all_columns()\n",
    "all_col_names = [col.Name for col in all_cols]\n",
    "\n",
    "for col_of_interest in profile_columns_of_interest:\n",
    "    if(all_col_names.count(col_of_interest) != 0):\n",
    "        existent_columns_of_interest.append(col_of_interest)\n",
    "\n",
    "print(existent_columns_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_profiles = \"\"\n",
    "error_profile_lines = error_profiles.splitlines()\n",
    "\n",
    "for line in error_profile_lines:\n",
    "    table_axes_values = line[line.find('(')+1:line.find(')')].split(',')\n",
    "    values = line.split(',')\n",
    "    column_name = values[0]\n",
    "    search_axis = values[1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1c5c7e3ef880e72ede146a6932d6b3c298665d2a627ade9775c999a53518742"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
