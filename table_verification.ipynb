{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum   \n",
    "\n",
    "class System(Enum):\n",
    "    PI3 = 1\n",
    "    PI4 = 2\n",
    "    FDP = 3\n",
    "\n",
    "system_in_use = System.PI3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create verification object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1728457 Rows\n"
     ]
    }
   ],
   "source": [
    "backend_cs_dll = 'table_verification_cs/bin/Debug/'\n",
    "sys.path.append(backend_cs_dll)\n",
    "\n",
    "import clr\n",
    "clr.AddReference('table_verification_cs')\n",
    "\n",
    "from TableVerification import TableVerifier, FailingProfile\n",
    "\n",
    "tv = TableVerifier(\"pi3b_asbuilt_pfc17500ab_2022-06-09\", \"B161087,B211100,B261087,B291060,B215008,B261008\")\n",
    "print(f\"Read {tv.GetNumRowsInDatatable()} Rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clr\n",
    "\n",
    "clr.AddReference('System')\n",
    "from System import String, Double\n",
    "from System.Collections.Generic import Dictionary\n",
    "\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "backend_cs_dll = '/nfs/home/brendan.posehn/ws/table_verification/table_verification_cs/bin/Debug/' # get some better way to do this \n",
    "sys.path.append(backend_cs_dll)\n",
    "clr.AddReference('table_verification_cs')\n",
    "\n",
    "from TableVerification import TableVerifier, FailingProfile\n",
    "\n",
    "fp = FailingProfile()\n",
    "fp.ProfileColumnName = \"B161087\"\n",
    "fp.SearchAxis = \"NevinsA\"\n",
    "\n",
    "tbl_params = Dictionary[String, Double]()\n",
    "tbl_params['psieq_soak'] = 0.08\n",
    "tbl_params['beta_pol1_setpoint'] = 0.1\n",
    "tbl_params['psieq_dc'] = -0.08\n",
    "tbl_params['NevinsC'] = 0.44\n",
    "tbl_params['NevinsN'] = 99\n",
    "tbl_params['CurrentRatio'] = 0.5\n",
    "fp.TableParams = tbl_params\n",
    "\n",
    "fp.OffendingValue = 1\n",
    "\n",
    "offending_vals = [0, 1, 2] # get this from tableaxes later on\n",
    "\n",
    "sys.path.append(os.getenv(\"AURORA_REPOS\"))\n",
    "\n",
    "from flagships.post_processing.GenerateColumns import get_full_file_path\n",
    "from flagships.post_processing.ParseFlagshipsFile import FlagshipsParser\n",
    "from flagships.post_processing.EquilibriumPlotting import PlotPsi5PctContours\n",
    "\n",
    "i = 1\n",
    "plt.figure(figsize=(12, 6))\n",
    "for val in offending_vals:\n",
    "    tbl_params[fp.SearchAxis] = val\n",
    "    filepath = get_full_file_path(\"\\\\mnt\\\\lut\\\\Flagships\\\\pi3b\\\\asbuilt\\\\pfc17500ab\\\\2022-06-09\\\\equil\", \"\", \".2022-06-09\",\n",
    "            soak = tbl_params['psieq_soak'], beta=tbl_params['beta_pol1_setpoint'], dc=tbl_params['psieq_dc'], NevinsC=tbl_params['NevinsC'], \n",
    "            NevinsAB=tbl_params['NevinsA'], NevinsN=tbl_params['NevinsN'], current_ratio=tbl_params['CurrentRatio'])\n",
    "    filepath = filepath.replace('\\\\', os.path.sep)\n",
    "    if(not os.path.exists(filepath)):\n",
    "        filepath = filepath[:filepath.find('ab', filepath.find('equil'))+3] + filepath[filepath.find('ab', filepath.find('equil'))+4:]\n",
    "    if(not os.path.exists(filepath)):\n",
    "        filepath = filepath[:filepath.rfind('ab')+3] + filepath[filepath.rfind('ab')+4:]\n",
    "    if(not os.path.exists(filepath)):\n",
    "        print(f'File cannot be found:\\n {filepath}')\n",
    "        continue\n",
    "    parser = FlagshipsParser(filepath, filepath)\n",
    "    plt.subplot(1, len(offending_vals), i)\n",
    "    i += 1\n",
    "    PlotPsi5PctContours(parser)\n",
    "    plt.title(fp.SearchAxis + f\" = {val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Check for holes in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check for data discontinuities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "print(os.getenv(\"AURORA_REPOS\"))\n",
    "sys.path.append(os.getenv(\"AURORA_REPOS\"))\n",
    "\n",
    "from flagships.post_processing import GenerateColumns\n",
    "\n",
    "if(system_in_use == System.PI3):\n",
    "    csv_generator =  GenerateColumns.PI3CSVGenerator()\n",
    "elif(system_in_use == System.PI4):\n",
    "    csv_generator =  GenerateColumns.PI4CSVGenerator()\n",
    "elif(system_in_use == System.FDP):\n",
    "    csv_generator = GenerateColumns.FDPCase22a_CSVGenerator()\n",
    "else:\n",
    "    print('Ensure correct system is set')\n",
    "\n",
    "other_cols = ['WBPol', 'q020', 'q050', 'q080', 'WBPolNoDCInFC', 'phiPlInFC']\n",
    "b_col_names = []\n",
    "for val in csv_generator.add_bprobe_columns([]):\n",
    "    b_col_names.append('B' + val[0])\n",
    "\n",
    "profile_columns_of_interest = other_cols + b_col_names\n",
    "existent_columns_of_interest = []\n",
    "\n",
    "all_cols = csv_generator.create_all_columns()\n",
    "all_col_names = [col.Name for col in all_cols]\n",
    "\n",
    "for col_of_interest in profile_columns_of_interest:\n",
    "    if(all_col_names.count(col_of_interest) != 0):\n",
    "        existent_columns_of_interest.append(col_of_interest)\n",
    "\n",
    "print(existent_columns_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_profiles = \"\"\n",
    "error_profile_lines = error_profiles.splitlines()\n",
    "\n",
    "for line in error_profile_lines:\n",
    "    table_axes_values = line[line.find('(')+1:line.find(')')].split(',')\n",
    "    values = line.split(',')\n",
    "    column_name = values[0]\n",
    "    search_axis = values[1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1c5c7e3ef880e72ede146a6932d6b3c298665d2a627ade9775c999a53518742"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
