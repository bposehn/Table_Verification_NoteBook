{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table Verification Notebook\n",
    "============\n",
    "\n",
    "Performs 2 main tasks:\n",
    "1. Flags table axis combinations which have column profiles (such as B probes) which have large enough 'Best to average poit removed fit quality' (see below). After these combinations have been flagged, their psi contours can be investigated by the user\n",
    "2. Finds table axis combinations which do not exist in the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textrm{Best to average point removed fit quality} = \\textrm{max}(\\textrm{abs}(\\chi_i - \\bar{\\chi}))$$\n",
    "Where $\\chi_i$ is the quadratic fit quality with point $i$ removed, and $\\bar{\\chi}$ is the average of all $\\chi_i$ for a single profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum   \n",
    "\n",
    "class System(Enum):\n",
    "    PI3 = 1\n",
    "    PI4 = 2\n",
    "    FDP = 3\n",
    "\n",
    "system_in_use = System.PI3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get profile names to best to average point removed fit quality of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_b_probe_colummns = True\n",
    "other_columns = ['WBPol', 'q020', 'q050', 'q080', 'WBPolNoDCInFC', 'phiPlInFC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getenv(\"AURORA_REPOS\"))\n",
    "\n",
    "from flagships.post_processing import GenerateColumns\n",
    "\n",
    "if(system_in_use == System.PI3):\n",
    "    csv_generator =  GenerateColumns.PI3CSVGenerator()\n",
    "elif(system_in_use == System.PI4):\n",
    "    csv_generator =  GenerateColumns.PI4CSVGenerator()\n",
    "elif(system_in_use == System.FDP):\n",
    "    csv_generator = GenerateColumns.FDPCase22a_CSVGenerator()\n",
    "else:\n",
    "    print('Ensure correct system is set')\n",
    "\n",
    "b_col_names = []\n",
    "if check_b_probe_colummns:\n",
    "    for val in csv_generator.add_bprobe_columns([]):\n",
    "        b_col_names.append('B' + val[0])\n",
    "\n",
    "profile_columns_of_interest = other_columns + b_col_names\n",
    "existent_columns_of_interest = []\n",
    "\n",
    "all_cols = csv_generator.create_all_columns()\n",
    "all_col_names = [col.Name for col in all_cols]\n",
    "\n",
    "for col_of_interest in profile_columns_of_interest:\n",
    "    if(all_col_names.count(col_of_interest) != 0):\n",
    "        existent_columns_of_interest.append(col_of_interest)\n",
    "\n",
    "print('Found the following columns: ', existent_columns_of_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create verification object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"pi3b_asbuilt_pfc17500ab_2022-06-09\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "backend_cs_dll = os.path.join('bin', 'Debug')\n",
    "sys.path.append(backend_cs_dll)\n",
    "\n",
    "existent_columns_of_interest = ['B161087','B211100','B261087','B291060','B215008','B261008','B291008']\n",
    "\n",
    "import clr\n",
    "clr.AddReference('table_verification_cs')\n",
    "\n",
    "from TableVerification import TableVerifier, FailingProfile\n",
    "\n",
    "# tv = TableVerifier(table_name, ','.join(existent_columns_of_interest))\n",
    "# tv = TableVerifier(\"pi3b_asbuilt_pfc17500ab_2022-06-09\", \"B161087,B211100,B261087,B291060,B215008,B261008,B291008\");\n",
    "verifier = TableVerifier(\"pi3b_asbuilt_pfc17500ab_2022-06-09\", \"B161087,B211100,B261087,B291060,B215008,B261008,B291008\")\n",
    "# print(f\"Read {tv.GetNumRowsInDatatable()} Rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flag abnormal profiles and view corresponding 5% psi contours\n",
    "\n",
    "First go through the table and score each profile for each table axis combination based on the best to average point removed fit quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier.GenerateProfileScores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use different thresholds to change how many profiles and table axis combinations would be flagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_flags_from_threshold(tv : TableVerifier, columns_of_interest : list[str], threshold : float):\n",
    "    profile_scores = tv.GetProfileScoreTable()\n",
    "\n",
    "    select_str = ''\n",
    "    for col in columns_of_interest:\n",
    "        select_str += f'{col} > {threshold} OR '\n",
    "    select_str = select_str[:-3]\n",
    "\n",
    "    failing_row_arr = profile_scores.Select(select_str)\n",
    "    failing_rows = profile_scores.Clone()\n",
    "\n",
    "    num_fails = 0\n",
    "    for row in failing_row_arr:\n",
    "        for col in columns_of_interest:\n",
    "            if row[col] > threshold:\n",
    "                num_fails += 1\n",
    "        failing_rows.ImportRow(row)\n",
    "\n",
    "    print(f'Table has {failing_rows.Rows.Count} flagged table axis configurations')\n",
    "    print(f'Table has {num_fails} flagged profiles')\n",
    "\n",
    "    axes_names = [col.ColumnName for col in failing_rows.Columns][0:7]\n",
    "\n",
    "    cs_float_type = type(row[columns_of_interest[0]])\n",
    "\n",
    "    print('\\nNumber of instances where certain table axes caused flag:')\n",
    "\n",
    "    # the search axis col is of type db.null (not float)\n",
    "    for axis_name in axes_names:\n",
    "        num_fails = 0\n",
    "        for row in failing_rows.Rows:\n",
    "            if type(row[axis_name]) != cs_float_type:\n",
    "                num_fails += 1\n",
    "        print(f'{axis_name}: {num_fails}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_flags_from_threshold(verifier, existent_columns_of_interest, 0.4)\n",
    "# Note that in a single row, multiple profiles can be flagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4\n",
    "failing_profiles = verifier.GetFailingProfiles(threshold)\n",
    "print('Found ', len(failing_profiles) , ' failing profiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot psi contours for flagging table axis configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.getenv(\"AURORA_REPOS\"))\n",
    "\n",
    "from flagships.post_processing.GenerateColumns import get_full_file_path\n",
    "from flagships.post_processing.ParseFlagshipsFile import FlagshipsParser\n",
    "from flagships.post_processing.EquilibriumPlotting import PlotPsi5PctContours\n",
    "        \n",
    "def plot_unique_fail_contours(failing_profiles : list[FailingProfile], axes):\n",
    "\n",
    "    unique_table_axes_combos = []\n",
    "    unique_table_axes_offending_names_and_values = []\n",
    "    for failing_profile in failing_profiles:\n",
    "        tbl_vals = {}\n",
    "        for pr in failing_profile.TableParams:\n",
    "            tbl_vals[pr.Key] = pr.Value\n",
    "        already_in_dict = False\n",
    "        for unique_table_axes_combo in unique_table_axes_combos:\n",
    "            if unique_table_axes_combo == tbl_vals:\n",
    "                already_in_dict = True\n",
    "                break\n",
    "        if not already_in_dict:\n",
    "            unique_table_axes_combos.append(tbl_vals)\n",
    "            unique_table_axes_offending_names_and_values.append((failing_profile.SearchAxis, failing_profile.TableParams[failing_profile.SearchAxis]))\n",
    "\n",
    "    filesLocation = failing_profiles[0].FilesLocation\n",
    "\n",
    "    for table_params, offending_name_and_value in zip(unique_table_axes_combos, unique_table_axes_offending_names_and_values):\n",
    "        search_axis_name = offending_name_and_value[0]\n",
    "        offending_value = offending_name_and_value[1]\n",
    "        search_axis_values = list(axes[search_axis_name])\n",
    "\n",
    "        if search_axis_values.index(offending_value) == 0:\n",
    "            offending_values = search_axis_values[:2]\n",
    "            offending_index = 0\n",
    "        elif search_axis_values.index(offending_value) == len(search_axis_values)-1:\n",
    "            offending_values = search_axis_values[len(search_axis_values)-2:]\n",
    "            offending_index = 1\n",
    "        else:\n",
    "            offending_values = search_axis_values[search_axis_values.index(offending_value)-1:search_axis_values.index(offending_value)+2]\n",
    "            offending_index = 1\n",
    "\n",
    "        i = 1\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for val in offending_values:\n",
    "            table_params[search_axis_name] = val\n",
    "            suffix = \".\" + os.path.normpath(filesLocation).split(os.sep)[-2]\n",
    "            prefix = \"\"\n",
    "            lut_root = os.path.normpath(os.getenv('FS_ARCHIVE_ROOT') + os.path.sep + filesLocation)\n",
    "            filepath = get_full_file_path(lut_root=lut_root, prefix=prefix, suffix=suffix,\n",
    "                    soak = table_params['psieq_soak'], beta=table_params['beta_pol1_setpoint'], dc=table_params['psieq_dc'], NevinsC=table_params['NevinsC'], \n",
    "                    NevinsAB=table_params['NevinsA'], NevinsN=table_params['NevinsN'], current_ratio=table_params['Ipl_setpoint']*1e-6)\n",
    "            filepath = filepath.replace('\\\\', os.path.sep)\n",
    "            if(not os.path.exists(filepath)):\n",
    "                filepath = filepath[:filepath.find('ab', filepath.find('equil'))+3] + filepath[filepath.find('ab', filepath.find('equil'))+4:]\n",
    "            if(not os.path.exists(filepath)):\n",
    "                filepath = filepath[:filepath.rfind('ab')+3] + filepath[filepath.rfind('ab')+4:]\n",
    "            if(not os.path.exists(filepath)):\n",
    "                print(f'File cannot be found:\\n {filepath}')\n",
    "                continue\n",
    "\n",
    "            print(filepath)\n",
    "            parser = FlagshipsParser(filepath, filepath)\n",
    "            plt.subplot(1, len(offending_values), i)\n",
    "            PlotPsi5PctContours(parser)\n",
    "            plt.scatter(parser.GetScalar('xpoint_r'), parser.GetScalar('xpoint_z'), marker='x') #TODO add this as a function to EquilmPlotting.py, but points dont look right\n",
    "            title = search_axis_name + f\" = {val}\"\n",
    "            if i-1 == offending_index :\n",
    "                title += \"\\n Offending Value\"\n",
    "            plt.title(title)\n",
    "            i += 1\n",
    "            \n",
    "        plt.show()\n",
    "        in_key = input(\"Press Enter to continue...\")\n",
    "        if(in_key == 'end'):\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique_fail_contours(failing_profiles, verifier.TableAxesValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for non existent table axes combinations\n",
    "<sub><sup>Currently takes about 15 minutes</sup></sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_configurations = verifier.CheckForHoles()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1c5c7e3ef880e72ede146a6932d6b3c298665d2a627ade9775c999a53518742"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
